---
title: "evolution of accessory glands: interaction with parental care and mating system"
date: "`r format(Sys.Date(), '%d %B %Y')`"
author: "Ben Bolker and Lucas Eckert"
output:
  html_document:
    code_folding: hide
bibliography: corHMM.bib	
---

```{r setup, message=FALSE}
source("R/utils.R")
source("R/mcmc.R")
source("R/functions.R")
load_pkgs()
zmargin <- theme(panel.spacing = grid::unit(0, "lines"))
theme_set(theme_bw())
library(targets)
```

The goal is to understand the role of paternal care of offspring (male parental care) and sperm competition in driving the evolution of accessory glands. While male parental care is a fairly unambiguous binary trait, sperm competition is harder to classify.  Here we use spawning context (pair spawning vs. group spawning) as a proxy for sperm competition. (**Note** from John Fitzpatrick: we should be careful how we phrase this, may want to replace "sperm competition" with "spawning behaviour" throughout. Leaving it alone for now, though.)

## data

Numbers of tips in each category (`pc` = male parental care; `sc` = sperm competition (i.e. group spawning); `ag` = accessory glands), depending on whether we use the partial (but fully genetically resolved) tree (`fishphylo`) or the imputed trees (`treeblock`).
	
```{r mosaic, eval=FALSE, echo=FALSE}
## cool but useless
(ag_compdata$data
  %>% mutate(ag = paste0("ag:",ag),
             pc = paste0("pc:",pc),
             sc = paste0("sc:",sc))
  %>% 
  ggplot() + 
  geom_mosaic(aes(x = product(pc, sc), fill = ag)) +
  geom_mosaic_text(aes(x = product(pc, sc), fill = ag), as.label = TRUE) +
  scale_fill_discrete_qualitative()
)
```

```{r barchart}
tar_load(ag_compdata)
tar_load(ag_compdata_tb)
barplot_trans <- (. 
  %>% mutate(across(c(pc, sc), factor, levels = c(0:1, "?")))
  %>% mutate(across(ag, factor, levels = 1:0)) ## reverse order to get ag=1 on top of bars
)
bar_data <- purrr::map_dfr(list(fishphylo = ag_compdata$data,
                    treeblock = ag_compdata_tb$data),
               barplot_trans,
               .id = "phylo")
gg1 <- (ggplot(bar_data, aes(x=pc, fill = ag))
  + geom_bar()
  + facet_grid(phylo~sc, labeller = label_both)
  + scale_fill_discrete_qualitative()
  + zmargin
)
print(gg1)
```                         

**fixme**: why is `Tylosurus_acus_melanotgus` but not in data? (It was causing an `NA` value in the `ag` legend)
**fixme**: this is drawn with the first treeblock example. Show which taxa are imputed? (Probably too much work, just note that some phylo structure is imputed ...)

```{r phylo_plot, message=FALSE, fig.width=8, fig.height=8}
## slow: cache?
tar_load(treeblock)
tar_load(ag_compdata_tb)
dd <- ag_compdata_tb$data
rownames(dd) <- dd$species
dd <- dd[,-1]
dd$ag <- factor(dd$ag)
dd[c("sc", "pc")] <- lapply(dd[c("sc", "pc")], factor, levels = c("0","1","?"))
## https://yulab-smu.top/treedata-book/chapter7.html

tt <- drop.tip(treeblock[[1]], setdiff(treeblock[[1]]$tip.label, rownames(dd)))
circ <- ggtree(tt, layout = "fan", open.angle=5)
p1 <- (gheatmap(circ, dd[,"ag", drop=FALSE], width=0.1)
  + scale_fill_manual(name = "ag", values=paste0("grey", c(90,10)))
  + new_scale_fill()
)
p2 <- (gheatmap(p1, dd[,"pc", drop=FALSE], width=0.1, offset=0.001)
  + scale_fill_manual(name = "pc", breaks = c("0", "1", "?"), values=c("darkblue", "lightblue", "grey50"))
  + new_scale_fill()
  )
p3 <- (gheatmap(p2, dd[,"sc", drop=FALSE], width=0.1, offset=0.002)
  + scale_fill_manual(name = "sc", breaks = c("0", "1", "?"), values=c("darkred", "pink", "grey50"))
  + new_scale_fill()
  )
print(p3)
```

Note that, across the entire phylogeny, accessory glands are (1) relatively rare (we knew this from the barplot above) and (2) phylogenetically concentrated (list families/clades in which they occur? Label them on the plot?) This means that any inference is likely be moderately difficult ...

## Likelihood comparison

The classic "dichotomanic" (= in love with dichotomous/discrete answers) ways to do this analysis would be to fit a series of nested models corresponding to specific null models/tests and 
(1) do likelihood ratio tests on pairs of nested models; (2) use information theoretic criteria (AIC/BIC/whatever) to rank the models/choose the best model. Pagel and Meade's reversible-jump MCMC machinery is a fancier way to do this; it's more general, testing all possible combinations of sets of equal rates, and gives a better [less approximate] estimate of the posterior probabilities of the different sub-models.

```{r likcomp, results="asis"}
ag_models <- paste0("ag_model_",
                    c("pcsc","pc","sc","indep"))
## tar_load(all_of(ag_models))
## needs to be done explicitly to keep targets pkg happy
tar_load("ag_model_pcsc")
tar_load("ag_model_pc")
tar_load("ag_model_sc")
tar_load("ag_model_indep")
atab <- as.data.frame(bbmle::AICtab(ag_model_indep, ag_model_pc, ag_model_sc, ag_model_pcsc,
                                    logLik = TRUE))
dtab <- data.frame(desc = c("AG dep on PC, SC & interaction",
                            "AG dep only on PC",
                            "AG dep only on SC",
                            "AG evol indep of PC, SC"),
                   row.names = ag_models)
atab2 <- merge(dtab, atab, by = 0) %>% dplyr::select(desc, dAIC, dLogLik, df) %>% arrange(dAIC)
knitr::kable(atab2, digits=1)
```

Show all likelihood ratio test comparisons.

```{r lrtest, fig.width=8, fig.height=8}
## want all
mnames <- gsub("ag_model_","",ag_models)[c(2,4,3,1)]
anfun <- function(m1, m2) {
    aa <- anova(m1,m2)
    sprintf("atop(Delta*dev==%1.1f,p==%1.1g)",
            ## "Δdev=%1.1f\np=%1.1g",
            aa$delta_dev[2], aa$pval[2])
}
A <- matrix(NA_character_,4,4,
            dimnames=list(mnames, mnames))
A["indep","pc"] <- anfun(ag_model_pc, ag_model_indep)
A["indep","sc"] <- anfun(ag_model_sc, ag_model_indep)
A["sc","pcsc"] <- anfun(ag_model_pcsc, ag_model_sc)
A["pc","pcsc"] <- anfun(ag_model_pcsc, ag_model_pc)
A["indep","pcsc"] <- anfun(ag_model_pcsc, ag_model_indep)
plotmat(A, curve = 0, box.size = 0.08)
```

- The likelihood comparisons and the AIC comparisons provide the same general conclusions.
- It would be interesting to compare an *additive* model (PC and SC independently influence AG evolution rate, but they don't interact) with the current interactive model, but it would require a little bit more machinery that I haven't implemented yet (most generally, creating rate sets as arbitrary linear combinations of parameters)

##  Priors

According to @pagel_bayesian_2006, the prior distributions on the rate parameters are determined as follows:

> We did not specify the mean or variance of the gamma but rather seeded its two parameters, normally labeled $a$ and $b$, by drawing from a uniform (0–10) hyperprior distribution. The use of a hyperprior allows the investigator to remain relatively uncommitted about the details of the prior distribution, allowing them to be estimated from the data. In most comparative studies, investigators have very little information about the mean and variance of the rate coefficients.

This is a mild overstatement: the hyperparameters induce their own distribution (see below).

@pagel_bayesian_2006 also comment that the prior scale also depends on the units in which branch length is measured.  The BayesTraits package provides an option to scale  branch lengths so that the *mean* branch length is 0.1 [@meade_bayestraits_2016].

```{r prior_calcs}
n <- 100000
set.seed(101)
r <- rgamma(n, shape = runif(n, 0, 10), scale = runif(n, 0, 10))
## BayesTrait scales *mean* branch length to 0.1
## in our case
tot_edge <- attr(treeblock[[1]], "orig_sumbranches")
n_edge <- length(treeblock[[1]]$edge.length)
## our mean branch length is 1/n_edge, Pagel & Meade's is 0.1
## Pagel & Meade's total branch length is 0.1*n_edge
ntip <- ape::Ntip(treeblock[[1]])
b <- log(c(0.1, 100*ntip))
m <- mean(b)
sd <- (b[2]-m)/3
## scale from log to log10
m <- m / log(10)
sd <- sd / log(10)
r_scaled <- r*(0.1*n_edge)
```

We tried to choose priors more mindfully. We started by scaling the branch lengths to set the *sum* of all the branch lengths (i.e. the total evolutionary time experienced by all lineages to 1). Event rates of discrete transitions are measured on the *hazard* scale (probability density of an event per unit time); a rate of $r$ corresponds to a mean of $r$ transitions per unit time. We therefore set the lower limit of our prior to 0.1, meaning an expectation of only a single transition over the entire tree. For a tree with $N$ species, we set the upper limit of the prior to $100 N$, i.e. an expectation of 100 transitions *per species*. These are obviously extreme values; we used a log-Normal prior with the (geometric) mean set halfway between these values (an expectation of `r round(exp(mean(b)))` events of the course of the tree, or `r round(exp(mean(b))/ntip)` events per species in our phylogeny of `r ntip` species), and the standard deviation set so that the range between the lower and upper limits is 6 SD. This range corresponds to a 0.26% prior probability that the rates are beyond the limits.

(Talk about uniform prior issues? [@yang_bayesian_2006; @carpenter_computational_2017; @thorson_uniform_2017])

**todo**: maybe it's no longer relevant, but does BayesTraits *really* use flat priors by default?? Double-check manual ...

```{r prior_plot, warning=FALSE}
## plot(density(r))
brkvec <- seq(-2,6, by =2)
ggplot(data.frame(r=r_scaled),
       aes(x=log10(r))) +
  geom_density(fill="grey") +
  stat_function(fun = function(x) dnorm(x, m, sd), geom ="area", col="blue", fill="blue", alpha=0.2) +
  scale_x_continuous(breaks = brkvec,
                     labels = 10^brkvec,
                     limits=c(-3,6),
                     sec.axis = sec_axis( ~ . - log10(ntip),
                                         name = "transitions per species",
                                         breaks = brkvec-3,
                                         labels = 10^(brkvec-3)
                                         )) +
  labs(y="prior probability density", x = "expected events per tree")
```

Here are the 95% quantile ranges of the prior distributions:

```{r prior_tab}
qq <- quantile(r, c(0.025, 0.975))
qqr <- qq*(0.1*n_edge)
rlims <- m + c(-1.96,1.96)*sd
qtab <- matrix(c(qqr, qqr/ntip, 10^rlims, 10^rlims/ntip), nrow=2, byrow=TRUE,
               dimnames = list(c("Pagel & Meade", "ours"),
                               c("min per tree", "max per tree", "min per species", "max per species")))
knitr::kable(as.data.frame(qtab), digits=3)
```

### Gain/loss priors

We also decided to put prior distributions on the ratio of gain rate to loss rate. (Need to put more discussion/justification here.)  This is less important since we also chose to fix the root (ancestral state) of the population at "no accessory glands, no paternal care, group rather pair spawning"; specifying this information should orient the tree and make it easier to distinguish losses from gains.

- `pc`: gain/loss ratio from 0.1 to 5
- `sc`: gain/loss ratio from 5 to 10
- `ag`: gain/loss ratio from 0.001 to 10

As with the priors on the rates, each of these ranges is used as the basis for 
a +/- 3 SD range (on the log scale) of the ratio.

```{r cifun}
tar_load(ag_model_pcsc)
tar_load(ag_mcmc0)
tar_load(all_ci)
```

Distribution of states in the tree (computed from stochastic character mapping, histograms represent 100 simulations):

```{r states, warning=FALSE}
tar_load(states_df)
pivot_longer(states_df, everything(), names_to = "state") %>%
  ggplot(aes(x=value)) + geom_histogram(bins=25) + facet_wrap(~state) + zmargin
## sum columns then divide by total to get sum == 1
states_avg <- apply(states_df, 2, sum, na.rm = TRUE) / sum(states_df, na.rm = TRUE)
```

Need to figure out weights e.g. if we want the intercept for `loss.ag` it should be  something like:

```{r wts, eval=FALSE}
tar_load(starts_with("contrast"))
intercept_loss <- sum(occ.ag0_pc{i}_sc{j} * loss.ag_pc{i}_sc{j})
pc_loss <- (sum(occ.ag0_pc1_sc{i} * loss.ag_pc1_sc{i}) - sum(occ.ag0_pc0_sc{i} * loss.ag_pc0_sc{i})) /
  sum(occ.ag0_pc{i}_sc{j})
```

etc. ...

**FIXME**: think more about net gain and how to characterize it.
Certainly should *not* be exponentiated, so leave it out here ...

```{r contr, eval=FALSE}
## playing with contrasts definitions/scaling
dd <- expand.grid(f1=letters[1:2], f2 = LETTERS[1:2])
m <- model.matrix(~f1*f2, data=dd, contrasts = list(f1=contr.sum, f2=contr.sum))
t(solve(m))
## cols 2 and 3 have magnitude 1/4 but we want 1/2 (diff between treatments, not dev between
## ttt and mean)
```

```{r wtd_contrasts}
tar_load(contrast_mat)
wts <- rep(NA, nrow(contrast_mat))
names(wts) <- rownames(contrast_mat)
snm <- names(states_avg)
wts["gain.sc"] <- sum(states_avg[grepl("sc0", snm)])  ## can gain sc whenever sc==0
wts["loss.sc"] <- sum(states_avg[grepl("sc1", snm)])  ##  "  lose  "    "     sc==1
wts["gain.pc"] <- sum(states_avg[grepl("pc0", snm)])  ## can gain pc whenever pc==0
wts["loss.pc"] <- sum(states_avg[grepl("pc1", snm)])  ##  "  lose pc    "     pc==1
## can gain ag when ag==0 are missing; fill in values for 
gain.ag_states <- grep("^gain.ag", names(wts), value = TRUE)
wts[gain.ag_states] <- states_avg[gsub("^gain.ag_", "ag0_", gain.ag_states)]
loss.ag_states <- grep("^loss.ag", names(wts), value = TRUE)
wts[loss.ag_states] <- states_avg[gsub("^loss.ag_", "ag1_", loss.ag_states)]

## scale contrast values by the time spent in the relevant state
contrast_mat_wt <- sweep(contrast_mat, 1, wts, "*")

## now scale each column (contrast) by the _total_ time spent in the relevant states
pos_mat <- contrast_mat != 0
storage.mode(pos_mat) <- "numeric"
col_vals <- colSums(sweep(pos_mat, 1, wts, "*"))
contrast_mat_wt <- sweep(contrast_mat_wt, 2, col_vals, "/")
##plot_grid(image_plot(contrast_mat), image_plot(contrast_mat_wt))
```

Hmm, not sure about weighted contrasts any more. It's tricky.

```{r plot_contrasts, fig.height=4, fig.width=10}
tar_load(contr_long_ag_mcmc0)
tar_load(contr_long_ag_mcmc_tb)
tar_load(contr_long_ag_priorsamp)
ag_contr_gainloss <- (purrr::map_dfr(list(fishphylo=contr_long_ag_mcmc0,
                                         treeblock=contr_long_ag_mcmc_tb,
                                         prior = contr_long_ag_priorsamp),
                                    filter, rate != "netgain",
                                    .id = "phylo")
    %>% mutate(across(phylo, factor,
                      levels=rev(c("prior","treeblock","fishphylo"))))
)
## ag_contr_gainloss %>% group_by(contrast, rate) %>% summarise(value=mean(value), .groups = "drop")
gg_sum <- ggplot(ag_contr_gainloss, aes(x = exp(value), y = rate)) +
  facet_wrap(~ contrast) +
  geom_violin(aes(fill = phylo), alpha=0.6) +
    stat_summary(fun.data = "median_hilow",
                 geom = "errorbar",
                 aes(group=phylo),
                 ## width by trial and error; not sure what determines this?
                 position = position_dodge(width=0.875),
                 colour = "red",
                 ## size = 2,
                 alpha = 0.5) +
    stat_summary(fun = median,
                 geom = "point", aes(group=phylo),
                 ## width by trial and error; not sure what determines this?
                 position = position_dodge(width=0.875),
                 colour = "black",
                 pch = 3,
                 size = 2) + 
  geom_vline(xintercept = 1, lty = 2) +
  scale_x_log10() +
  zmargin +
  ## scale_fill_discrete_qualitative() +
  scale_fill_grey(guide = guide_legend(reverse = TRUE)) +
  ## scale_colour_discrete_qualitative() +
  labs(x="expected transitions/proportional difference in rates")
print(gg_sum)
```

- Red bars are 95% (quantile) confidence intervals.
- Conclusions
    - priors are more constraining than I thought (is that partly because the constraints represent sums of independent prior values, so they get 'shrunk'?)
   - fishphylo/treeblock results differ very little (treeblock results are *slightly* stronger, especially if we're fixated on significance at the 5% level)
   - gain/loss intercepts differ/are asymmetric because of the priors we used.

```{r}
tar_load(contr_long_ag_mcmc0)
tar_load(contr_long_ag_mcmc_tb)
tar_load(contr_long_ag_priorsamp)
ag_contr_gainloss <- (purrr::map_dfr(list(fishphylo=contr_long_ag_mcmc0,
                                         treeblock=contr_long_ag_mcmc_tb,
                                         prior = contr_long_ag_priorsamp),
                                    filter, rate != "netgain",
                                    .id = "phylo")
    %>% mutate(across(phylo, factor,
                      levels=rev(c("prior","treeblock","fishphylo"))))
    ## but we only care about treeblock for the paper
    %>% filter(phylo == "treeblock")
)
gg_sum <- ggplot(ag_contr_gainloss, aes(x = exp(value), y = contrast, colour = rate)) +
    geom_violin(aes(fill = rate), alpha=0.6) +
    stat_summary(fun.data = "median_hilow",
                 geom = "errorbar",
                 aes(group=rate),
                 ## width by trial and error; not sure what determines this?
                 position = position_dodge(width=0.875),
                 colour = "black") +
    stat_summary(fun = median,
                 geom = "point", aes(group=rate),
                 ## width by trial and error; not sure what determines this?
                 position = position_dodge(width=0.875),
                 colour = "black",
                 pch = 3,
                 size = 2) + 
  geom_vline(xintercept = 1, lty = 2) +
  scale_x_log10(labels = function(x) format(x, scientific = FALSE)) +
  zmargin +
  scale_colour_manual(name="", labels = c("Gain","Loss"), values = c("firebrick","royalblue"))+
  scale_fill_manual(name="", labels = c("Gain","Loss"), values = c("firebrick","royalblue"))+
  scale_y_discrete(breaks=c("intercept","pcxsc","sc","pc"), 
                   labels=c("Intercept", "Interaction", "Spawning Mode", "Parental Care"),
                   limits=c("intercept","pcxsc","sc","pc"))+
  labs(x="Proportional Difference in Rates", y="")+
  theme(panel.grid = element_blank(),
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.text = element_text(size = 10, color = "black"),
        axis.title.x = element_text(size = 12))
print(gg_sum)
```


```{r, echo = FALSE, eval = FALSE}
## double-checking bar width for sc gain/treeblock: visual discrepancy (Hmisc::smedian.hilow) with table below (quantiles)?
ggb <- ggplot_build(gg_sum)
ggb$data[[2]] %>% dplyr::select(group, PANEL, x, y, xmin, xmax) %>% mutate(across(where(is.numeric), ~ . * log(10)))
filter(ag_contr_gainloss, contrast == "sc", rate == "gain", phylo == "treeblock") %>%
  pull(value) %>% Hmisc::smedian.hilow()
```

Only showing treeblock (preferred) results ...
```{r sum_tab, results="asis"}
bayes_pval <- function(x, ref=0) {
  x <- mean(x<ref)
  2 * min(x, 1-x)
}
(ag_contr_gainloss
  %>% group_by(phylo,contrast,rate)
  %>% summarise(median = median(value), lwr = quantile(value, 0.025), upr = quantile(value, 0.975), p = bayes_pval(value), .groups = "drop")
  %>% filter(phylo == "treeblock")
  %>% dplyr::select(-phylo)
  %>% mutate(across(c(median, lwr, upr), exp))
  %>% mutate(across(p, ~ ifelse(contrast=="intercept", NA, .)))
  %>% knitr::kable(digits = 3)
)
```

**Conclusion**: treeblock and fishphylo results are nearly identical, treeblock results are *slightly* clearer.

Graphing all CIs: bounds are set to the lower/upper bounds used for corHMM fit. Vertical lines show the mean and ± 2 SD of the priors.

**fixme**: understand why average rates are so high, loss rates > gain rates?  Does this have something to do with not weighting? (i.e. loss can only operate when AG is present, which is rare)?


```{r ci_plot}
tar_load(prior_ci)
## order of parameters
levs <- c(outer(FUN = paste, sep = ".",
      c("loss", "gain"),
      c("sc", "pc",
        paste0("ag_", c(outer(paste0("pc", 0:1), paste0("sc", 0:1), paste, sep = "_"))))
      ))
corhmm_bounds <- log(c(lwr=0.1, upper = 100*ape::Ntip(ag_compdata$phy)))
corhmm_prior <- log(c(lwr=1, upper = 10*ape::Ntip(ag_compdata$phy)))
corhmm_mid <- mean(corhmm_bounds)
all_ci <- all_ci %>% replace_na(list(upr = Inf, lwr = -Inf)) %>%
  mutate(across(term, factor, levels = levs))
## extend NA confidence interval to limit of graph
ggplot(
    all_ci,
    aes(term, exp(estimate), colour = method, shape = method)
) +
    geom_pointrange(position = position_dodge(width = 0.5),
                    aes(ymin = exp(lwr), ymax = exp(upr))) +
    scale_colour_discrete_qualitative(guide=guide_legend(reverse=TRUE)) +
    scale_y_log10(limits = exp(corhmm_bounds), oob = scales::squish) +
    coord_flip() +
    labs(y="rate", x = "") +
    geom_point(data = tidyr::pivot_longer(prior_ci, -term),
               aes(y = exp(value)), shape = 16, size = 2, colour = "gray")
## geom_hline(yintercept =exp(corhmm_mid), lty=2) +
## geom_hline(yintercept = exp(corhmm_prior), lty=2, col="gray")
```

Not sure if we can do something pretty with character mappings ... ? reduce to trait-by-trait maps?

```{r stochmap, message=FALSE}
set.seed(1)
sm0 <- with(ag_model_pcsc,
            makeSimmap(phy, data, solution, rate.cat, nSim = 1))
sm0[[1]]$tip.label[] <- ""
nm <- rownames(sm0[[1]]$Q)
## cols <- setNames(colorspace::qualitative_hcl(length(nm)), seq(nm))
cols <- setNames(iwanthue(length(nm)), seq(nm))
phytools::plotSimmap(sm0[[1]], type="fan", colors = cols,
                     mar=c(2,2,2,8))
par(mar=c(0,0,0,0), new=TRUE)
plot(0:1,0:1, type="n", ann=FALSE)
legend("topright", col = cols, legend=nm, lty = 1, lwd=2)
```

**fixme**: combine with circplot for tip states? use strong palette distinction between ag/non-ag colours?

---

## to do

### logistical

- compose e-mail to Beaulieu, O'Meara et al

### technical

- reimplement as [target markdown](https://books.ropensci.org/targets/markdown.html#markdown) ?
- switch violin plots to pointrange (or 50/90 pointranges)?
- dot-whisker plot comparing the parameters of the restricted models
- 

### statistical

- implement weighting by branch state: for a given focal trait (`ag`) and modifier (`sc`), want to weight the elements of the contrast only by the *non-focal* trait (e.g. if `w_pc0` and `w_pc1 = 1-w_pc0` are the overall fractions of time that the branches are in the corresponding states, then we want the `sc_loss` contrast to be `w_pc0*(loss.ag_pc0_sc1-loss.ag_pc0_sc0) + (1-w_pc0)*(loss.ag_pc1_sc1-loss.ag_pc1_sc0)`. (The factors in front of the parenthesized terms are currently 1/2.) Similar expressions would apply to the gain term and to the `pc` analogues.
- why does the result from the AIC/LRT results seem so much stronger than the Bayesian results? e.g., compare the LRT test p-values with the parameter-level Bayesian p-values. The pc-vs-indep and sc-vs-indep p-values are extremely strong; why isn't this matched by the parameter p-values? (We can still argue that the Bayesian results are more interpretable etc. - and if we want to look at parameter values and uncertainties, we really need Bayes - but it is a little disappointing, and surprising.)

---

## References

